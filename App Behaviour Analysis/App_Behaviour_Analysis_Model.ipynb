{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Model and Testing \n",
    "\n",
    "We will be utilising our new cleaned data in building our model and testing it for accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the Libraries and the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"new_appdata_self.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = dataset[\"enrolled\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    1\n",
       "4    1\n",
       "Name: enrolled, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.drop(columns = \"enrolled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(dataset, target, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 49)\n",
      "(10000, 49)\n",
      "(40000,)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We have userIDs which we do not require for the model building but will be later required for referencing\n",
    "train_identifier = X_train[\"user\"]\n",
    "test_identifier = X_test[\"user\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(columns = \"user\")\n",
    "X_test = X_test.drop(columns = \"user\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "stand_scale = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since Standard Scaler returns a numpy array, it loses column names and index which will be used later for model building\n",
    "X_train2 = pd.DataFrame(stand_scale.fit_transform(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test2 = pd.DataFrame(stand_scale.transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2.columns = X_train.columns.values\n",
    "X_test2.columns = X_test.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2.index = X_train.index.values\n",
    "X_test2.index = X_test.index.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bringing back scaled observations back to original training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train2\n",
    "X_test = X_test2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#L1 Reguliarization Model to compensate for the screen correlations and other correlations which we may not know about\n",
    "classifier = LogisticRegression(random_state = 0, penalty = 'l1') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l1',\n",
       "                   random_state=0, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7681"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_sc = accuracy_score(y_test, y_pred)\n",
    "accuracy_sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7618952017667135"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_sc = precision_score(y_test, y_pred)\n",
    "precision_sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7700892857142857"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_sc = recall_score(y_test, y_pred) \n",
    "recall_sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7659703300030276"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_sc = f1_score(y_test, y_pred)\n",
    "f1_sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__All 3 scores are approximately equal therefore our model is in good state.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data Accuracy: 0.7681\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_conf_matrix = pd.DataFrame(conf_matrix, index = (0, 1), columns = (0, 1))\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.set(font_scale=1.4)\n",
    "sns.heatmap(df_conf_matrix, annot=True, fmt='g')\n",
    "print(\"Test Data Accuracy: {:.4f}\".format(accuracy_sc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation for the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ptpar\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\ptpar\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\ptpar\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\ptpar\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\ptpar\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\ptpar\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\ptpar\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\ptpar\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\ptpar\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\ptpar\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "accuracies_cross_val = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Accuracy: 0.767 (+/- 0.010)\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Accuracy: {:.3f} (+/- {:.3f})\".format(accuracies_cross_val.mean(), accuracies_cross_val.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Results Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results = pd.concat([y_test, test_identifier], axis = 1).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results['Predicted_Results'] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>enrolled</th>\n",
       "      <th>Predicted_Results</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>239786</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>279644</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>98290</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>170150</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>237568</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>65042</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>207226</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>363062</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>152296</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>64484</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>38108</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>359940</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>136089</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14231</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>216038</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>18918</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>316730</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>28308</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>228387</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>69640</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>358264</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>348059</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>178743</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>167556</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>294101</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>192801</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>163983</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>298830</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>151790</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>20200</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9970</th>\n",
       "      <td>348989</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9971</th>\n",
       "      <td>248593</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9972</th>\n",
       "      <td>316086</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9973</th>\n",
       "      <td>192540</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9974</th>\n",
       "      <td>256833</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9975</th>\n",
       "      <td>273991</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9976</th>\n",
       "      <td>365937</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9977</th>\n",
       "      <td>295129</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9978</th>\n",
       "      <td>255715</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9979</th>\n",
       "      <td>37332</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9980</th>\n",
       "      <td>164886</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9981</th>\n",
       "      <td>309967</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9982</th>\n",
       "      <td>14907</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9983</th>\n",
       "      <td>244737</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9984</th>\n",
       "      <td>284862</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9985</th>\n",
       "      <td>60719</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9986</th>\n",
       "      <td>262103</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9987</th>\n",
       "      <td>243679</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9988</th>\n",
       "      <td>280000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9989</th>\n",
       "      <td>255074</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9990</th>\n",
       "      <td>347521</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9991</th>\n",
       "      <td>335029</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9992</th>\n",
       "      <td>37271</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9993</th>\n",
       "      <td>240006</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9994</th>\n",
       "      <td>279449</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>143036</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>91158</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>248318</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>142418</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>279355</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user  enrolled  Predicted_Results\n",
       "0     239786         1                  1\n",
       "1     279644         1                  1\n",
       "2      98290         0                  0\n",
       "3     170150         1                  1\n",
       "4     237568         1                  1\n",
       "5      65042         1                  0\n",
       "6     207226         1                  1\n",
       "7     363062         0                  0\n",
       "8     152296         1                  1\n",
       "9      64484         0                  0\n",
       "10     38108         1                  1\n",
       "11    359940         0                  0\n",
       "12    136089         0                  0\n",
       "13     14231         1                  1\n",
       "14    216038         0                  0\n",
       "15     18918         1                  1\n",
       "16    316730         1                  1\n",
       "17     28308         1                  0\n",
       "18    228387         1                  0\n",
       "19     69640         1                  1\n",
       "20    358264         0                  0\n",
       "21    348059         0                  0\n",
       "22    178743         1                  1\n",
       "23    167556         0                  0\n",
       "24    294101         0                  0\n",
       "25    192801         0                  1\n",
       "26    163983         1                  1\n",
       "27    298830         0                  0\n",
       "28    151790         1                  1\n",
       "29     20200         1                  1\n",
       "...      ...       ...                ...\n",
       "9970  348989         0                  1\n",
       "9971  248593         1                  0\n",
       "9972  316086         1                  1\n",
       "9973  192540         1                  1\n",
       "9974  256833         0                  0\n",
       "9975  273991         1                  1\n",
       "9976  365937         0                  0\n",
       "9977  295129         0                  0\n",
       "9978  255715         1                  0\n",
       "9979   37332         0                  1\n",
       "9980  164886         1                  1\n",
       "9981  309967         0                  1\n",
       "9982   14907         0                  0\n",
       "9983  244737         1                  1\n",
       "9984  284862         0                  1\n",
       "9985   60719         1                  1\n",
       "9986  262103         1                  0\n",
       "9987  243679         1                  1\n",
       "9988  280000         1                  1\n",
       "9989  255074         0                  0\n",
       "9990  347521         0                  0\n",
       "9991  335029         1                  0\n",
       "9992   37271         1                  0\n",
       "9993  240006         1                  1\n",
       "9994  279449         0                  1\n",
       "9995  143036         1                  0\n",
       "9996   91158         1                  1\n",
       "9997  248318         0                  0\n",
       "9998  142418         1                  1\n",
       "9999  279355         1                  1\n",
       "\n",
       "[10000 rows x 3 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_results[['user', 'enrolled', 'Predicted_Results']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We have created a model that will label every new user as \"highly likely\" or \"unlikely\" to subscribe. We can further validate our results by running our predictions on daily new installs, and see whether our accuracy is consistent. From therem we can narrow our marketing only to those \"unlikely\" users.\n",
    "\n",
    "\n",
    "- The increase in overall subscriptions can measure the benefit of this model to the company. We know that those who are already likely to be subscriped will do so however we can push them with new offers but with less discounts than those who are completely unlikely to join.\n",
    "\n",
    "\n",
    "- Solutions to unlikely users could be offers such as 50% off for yearly subscription. Such an offer will ensure that they are bound to the app for an extended period of time\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
